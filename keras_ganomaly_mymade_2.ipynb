{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ganomaly.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fOFzTCbXTfi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bab7bf0a-2ee3-4224-9bc3-c2081e2de039"
      },
      "source": [
        "from keras import layers\n",
        "import keras\n",
        "import keras.backend as K\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAzGntqyX583",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj9m8quMYrtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "width = 64\n",
        "height = 64\n",
        "channels = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V6k5E4HX8ns",
        "colab_type": "text"
      },
      "source": [
        "## Generators Encoder\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SSgbWtgYFge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_layer = layers.Input(name='input', shape=(height, width, channels))\n",
        "\n",
        "# Encoder\n",
        "x = layers.Conv2D(32, (5,5), strides=(1,1), padding='same', name='conv_1', kernel_regularizer = 'l2')(input_layer)\n",
        "x = layers.LeakyReLU(name='leaky_1')(x)\n",
        "\n",
        "x = layers.Conv2D(64, (3,3), strides=(2,2), padding='same', name='conv_2', kernel_regularizer = 'l2')(x)\n",
        "x = layers.BatchNormalization(name='norm_1')(x)\n",
        "x = layers.LeakyReLU(name='leaky_2')(x)\n",
        "\n",
        "\n",
        "x = layers.Conv2D(128, (3,3), strides=(2,2), padding='same', name='conv_3', kernel_regularizer = 'l2')(x)\n",
        "x = layers.BatchNormalization(name='norm_2')(x)\n",
        "x = layers.LeakyReLU(name='leaky_3')(x)\n",
        "\n",
        "\n",
        "x = layers.Conv2D(128, (3,3), strides=(2,2), padding='same', name='conv_4', kernel_regularizer = 'l2')(x)\n",
        "x = layers.BatchNormalization(name='norm_3')(x)\n",
        "x = layers.LeakyReLU(name='leaky_4')(x)\n",
        "\n",
        "x = layers.GlobalAveragePooling2D(name='g_encoder_output')(x)\n",
        "\n",
        "g_e = keras.models.Model(inputs=input_layer, outputs=x)\n",
        "\n",
        "g_e.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsFGE97WYMts",
        "colab_type": "text"
      },
      "source": [
        "## Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pivNg2CMYQwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_layer = layers.Input(name='input', shape=(height, width, channels))\n",
        "\n",
        "x = g_e(input_layer)\n",
        "\n",
        "y = layers.Dense(width * width * 2, name='dense')(x) # 2 = 128 / 8 / 8\n",
        "y = layers.Reshape((width//8, width//8, 128), name='de_reshape')(y)\n",
        "\n",
        "y = layers.Conv2DTranspose(128, (3,3), strides=(2,2), padding='same', name='deconv_1', kernel_regularizer = 'l2')(y)\n",
        "y = layers.LeakyReLU(name='de_leaky_1')(y)\n",
        "\n",
        "y = layers.Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', name='deconv_2', kernel_regularizer = 'l2')(y)\n",
        "y = layers.LeakyReLU(name='de_leaky_2')(y)\n",
        "\n",
        "y = layers.Conv2DTranspose(32, (3,3), strides=(2,2), padding='same', name='deconv_3', kernel_regularizer = 'l2')(y)\n",
        "y = layers.LeakyReLU(name='de_leaky_3')(y)\n",
        "\n",
        "y = layers.Conv2DTranspose(channels, (1, 1), strides=(1,1), padding='same', name='decoder_deconv_output', kernel_regularizer = 'l2', activation='tanh')(y)\n",
        "\n",
        "g = keras.models.Model(inputs=input_layer, outputs=y)\n",
        "\n",
        "g.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xJahMZrZReX",
        "colab_type": "text"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coa6bXCRYRG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_layer = layers.Input(name='input', shape=(height, width, channels))\n",
        "\n",
        "z = layers.Conv2D(32, (5,5), strides=(1,1), padding='same', name='encoder_conv_1', kernel_regularizer = 'l2')(input_layer)\n",
        "z = layers.LeakyReLU()(z)\n",
        "\n",
        "z = layers.Conv2D(64, (3,3), strides=(2,2), padding='same', name='encoder_conv_2', kernel_regularizer = 'l2')(z)\n",
        "z = layers.BatchNormalization(name='encoder_norm_1')(z)\n",
        "z = layers.LeakyReLU()(z)\n",
        "\n",
        "\n",
        "z = layers.Conv2D(128, (3,3), strides=(2,2), padding='same', name='encoder_conv_3', kernel_regularizer = 'l2')(z)\n",
        "z = layers.BatchNormalization(name='encoder_norm_2')(z)\n",
        "z = layers.LeakyReLU()(z)\n",
        "\n",
        "z = layers.Conv2D(128, (3,3), strides=(2,2), padding='same', name='conv_41', kernel_regularizer = 'l2')(z)\n",
        "z = layers.BatchNormalization(name='encoder_norm_3')(z)\n",
        "z = layers.LeakyReLU()(z)\n",
        "\n",
        "z = layers.GlobalAveragePooling2D(name='encoder_output')(z)\n",
        "\n",
        "encoder = keras.models.Model(input_layer, z)\n",
        "encoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHU8SoiCZUCH",
        "colab_type": "text"
      },
      "source": [
        "## feature extractor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tovsU-1uZXzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_layer = layers.Input(name='input', shape=(height, width, channels))\n",
        "\n",
        "f = layers.Conv2D(32, (5,5), strides=(1,1), padding='same', name='f_conv_1', kernel_regularizer = 'l2')(input_layer)\n",
        "f = layers.LeakyReLU(name='f_leaky_1')(f)\n",
        "\n",
        "f = layers.Conv2D(64, (3,3), strides=(2,2), padding='same', name='f_conv_2', kernel_regularizer = 'l2')(f)\n",
        "f = layers.BatchNormalization(name='f_norm_1')(f)\n",
        "f = layers.LeakyReLU(name='f_leaky_2')(f)\n",
        "\n",
        "\n",
        "f = layers.Conv2D(128, (3,3), strides=(2,2), padding='same', name='f_conv_3', kernel_regularizer = 'l2')(f)\n",
        "f = layers.BatchNormalization(name='f_norm_2')(f)\n",
        "f = layers.LeakyReLU(name='f_leaky_3')(f)\n",
        "\n",
        "\n",
        "f = layers.Conv2D(128, (3,3), strides=(2,2), padding='same', name='f_conv_4', kernel_regularizer = 'l2')(f)\n",
        "f = layers.BatchNormalization(name='f_norm_3')(f)\n",
        "f = layers.LeakyReLU(name='feature_output')(f)\n",
        "\n",
        "feature_extractor = keras.models.Model(input_layer, f)\n",
        "\n",
        "feature_extractor.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7HBx1GiZhm-",
        "colab_type": "text"
      },
      "source": [
        "## gan trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bosacIf7ZkZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AdvLoss(keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AdvLoss, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        ori_feature = feature_extractor(x[0])\n",
        "        gan_feature = feature_extractor(x[1])\n",
        "        return K.mean(K.square(ori_feature - K.mean(gan_feature, axis=0)))\n",
        "\n",
        "    def get_output_shape_for(self, input_shape):\n",
        "        return (input_shape[0][0], 1)\n",
        "    \n",
        "class CntLoss(keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(CntLoss, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        ori = x[0]\n",
        "        gan = x[1]\n",
        "        return K.mean(K.abs(ori - gan))\n",
        "\n",
        "    def get_output_shape_for(self, input_shape):\n",
        "        return (input_shape[0][0], 1)\n",
        "    \n",
        "class EncLoss(keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(EncLoss, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        ori = x[0]\n",
        "        gan = x[1]\n",
        "        return K.mean(K.square(g_e(ori) - encoder(gan)))\n",
        "\n",
        "    def get_output_shape_for(self, input_shape):\n",
        "        return (input_shape[0][0], 1)\n",
        "    \n",
        "# model for training\n",
        "input_layer = layers.Input(name='input', shape=(height, width, channels))\n",
        "gan = g(input_layer) # g(x)\n",
        "\n",
        "adv_loss = AdvLoss(name='adv_loss')([input_layer, gan])\n",
        "cnt_loss = CntLoss(name='cnt_loss')([input_layer, gan])\n",
        "enc_loss = EncLoss(name='enc_loss')([input_layer, gan])\n",
        "\n",
        "gan_trainer = keras.models.Model(input_layer, [adv_loss, cnt_loss, enc_loss])\n",
        "\n",
        "# loss function\n",
        "def loss(yt, yp):\n",
        "    return yp\n",
        "\n",
        "losses = {\n",
        "    'adv_loss': loss,\n",
        "    'cnt_loss': loss,\n",
        "    'enc_loss': loss,\n",
        "}\n",
        "\n",
        "lossWeights = {'cnt_loss': 20.0, 'adv_loss': 1.0, 'enc_loss': 1.0}\n",
        "\n",
        "# compile\n",
        "gan_trainer.compile(optimizer = 'adam', loss=losses, loss_weights=lossWeights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YlrDrqZUfJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gan_trainer.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWWVBPizZctk",
        "colab_type": "text"
      },
      "source": [
        "## discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcJdjTerZbMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_layer = layers.Input(name='input', shape=(height, width, channels))\n",
        "\n",
        "f = feature_extractor(input_layer)\n",
        "\n",
        "d = layers.GlobalAveragePooling2D(name='glb_avg')(f)\n",
        "d = layers.Dense(1, activation='sigmoid', name='d_out')(d)\n",
        "    \n",
        "d = keras.models.Model(input_layer, d)\n",
        "d.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6d91GYncIGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6f6m8x7bDUX",
        "colab_type": "text"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oniqQC4ZbN06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_ok = x_train[y_train == 1] # 6742 筆\n",
        "x_test = x_test[(y_test == 7) | (y_test == 1)] # 1135 筆 \"1\", 1028 筆 \"7\"\n",
        "y_test = y_test[(y_test == 7) | (y_test == 1)]\n",
        "\n",
        "def reshape_x(x):\n",
        "    new_x = np.empty((len(x), width, height))\n",
        "    for i, e in enumerate(x):\n",
        "        new_x[i] = cv2.resize(e, (width, height))\n",
        "    return np.expand_dims(new_x, axis=-1) / 127 - 1\n",
        "  \n",
        "x_ok = reshape_x(x_ok)\n",
        "x_test = reshape_x(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEX22tJD7DUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvxWqaXtbTS4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_ok.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxPzCEC1bFMR",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDYFHg6Iboh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "niter = 1000\n",
        "bz = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53rLCTe3a8LY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data_generator(data, batch_size=32):\n",
        "    datalen = len(data)\n",
        "    cnt = 0\n",
        "    while True:\n",
        "        idxes = np.arange(datalen)\n",
        "        np.random.shuffle(idxes)\n",
        "        cnt += 1\n",
        "        for i in range(int(np.ceil(datalen/batch_size))):\n",
        "            train_x = np.take(data, idxes[i*batch_size: (i+1) * batch_size], axis=0)\n",
        "            y = np.ones(len(train_x))\n",
        "            yield train_x, [y, y, y]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHQxiAHia_5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_generator = get_data_generator(x_ok, bz)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKkjwML7bjqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(niter):\n",
        "    ### get batch x, y ###\n",
        "    x, y = train_data_generator.__next__()\n",
        "    ### train disciminator ###\n",
        "    d.trainable = True\n",
        "    fake_x = g.predict(x)\n",
        "    d_x = np.concatenate([x, fake_x], axis=0)\n",
        "    d_y = np.concatenate([np.zeros(len(x)), np.ones(len(fake_x))], axis=0)\n",
        "    d_loss = d.train_on_batch(d_x, d_y)\n",
        "    ### train generator ###\n",
        "    d.trainable = False \n",
        "    g_loss = gan_trainer.train_on_batch(x, y)\n",
        "    #g_loss include adv cnt enc loss, and what is last one ?\n",
        "\n",
        "    if i % 50 == 0:\n",
        "        print(f'niter: {i+1}, g_loss: {g_loss}, d_loss: {d_loss}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cHDcccacdST",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXAufnuIbuvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded = g_e.predict(x_test)\n",
        "gan_x = g.predict(x_test)\n",
        "encoded_gan = g_e.predict(gan_x)\n",
        "score = np.sum(np.absolute(encoded - encoded_gan), axis=-1)\n",
        "score = (score - np.min(score)) / (np.max(score) - np.min(score)) # map to 0~1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k8DiAAZdeZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 14, 5\n",
        "plt.scatter(range(len(x_test)), score, c=['skyblue' if x == 1 else 'pink' for x in y_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnGVWtjjdtFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "niter = 9000\n",
        "bz = 32\n",
        "\n",
        "for i in range(niter):\n",
        "    ### get batch x, y ###\n",
        "    x, y = train_data_generator.__next__()\n",
        "    ### train disciminator ###\n",
        "    d.trainable = True\n",
        "    fake_x = g.predict(x)\n",
        "    d_x = np.concatenate([x, fake_x], axis=0)\n",
        "    d_y = np.concatenate([np.zeros(len(x)), np.ones(len(fake_x))], axis=0)\n",
        "    d_loss = d.train_on_batch(d_x, d_y)\n",
        "    ### train generator ###\n",
        "    d.trainable = False \n",
        "    g_loss = gan_trainer.train_on_batch(x, y)\n",
        "    #g_loss include adv cnt enc loss, and what is last one ?\n",
        "\n",
        "    if i % 50 == 0:\n",
        "        print(f'niter: {i+1}, g_loss: {g_loss}, d_loss: {d_loss}')\n",
        "\n",
        "encoded = g_e.predict(x_test)\n",
        "gan_x = g.predict(x_test)\n",
        "encoded_gan = g_e.predict(gan_x)\n",
        "score = np.sum(np.absolute(encoded - encoded_gan), axis=-1)\n",
        "score = (score - np.min(score)) / (np.max(score) - np.min(score)) # map to 0~1\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 14, 5\n",
        "plt.scatter(range(len(x_test)), score, c=['skyblue' if x == 1 else 'pink' for x in y_test])\n",
        "\n",
        "#sum 10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZGNIltydtAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "niter = 10000\n",
        "bz = 32\n",
        "\n",
        "for i in range(niter):\n",
        "    ### get batch x, y ###\n",
        "    x, y = train_data_generator.__next__()\n",
        "    ### train disciminator ###\n",
        "    d.trainable = True\n",
        "    fake_x = g.predict(x)\n",
        "    d_x = np.concatenate([x, fake_x], axis=0)\n",
        "    d_y = np.concatenate([np.zeros(len(x)), np.ones(len(fake_x))], axis=0)\n",
        "    d_loss = d.train_on_batch(d_x, d_y)\n",
        "    ### train generator ###\n",
        "    d.trainable = False \n",
        "    g_loss = gan_trainer.train_on_batch(x, y)\n",
        "    #g_loss include adv cnt enc loss, and what is last one ?\n",
        "\n",
        "    if i % 50 == 0:\n",
        "        print(f'niter: {i+1}, g_loss: {g_loss}, d_loss: {d_loss}')\n",
        "\n",
        "encoded = g_e.predict(x_test)\n",
        "gan_x = g.predict(x_test)\n",
        "encoded_gan = g_e.predict(gan_x)\n",
        "score = np.sum(np.absolute(encoded - encoded_gan), axis=-1)\n",
        "score = (score - np.min(score)) / (np.max(score) - np.min(score)) # map to 0~1\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 14, 5\n",
        "plt.scatter(range(len(x_test)), score, c=['skyblue' if x == 1 else 'pink' for x in y_test])\n",
        "\n",
        "#sum 20000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tQ7UT26ds_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO_QbKNwds72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "niter = 80000\n",
        "bz = 32\n",
        "\n",
        "for i in range(niter):\n",
        "    ### get batch x, y ###\n",
        "    x, y = train_data_generator.__next__()\n",
        "    ### train disciminator ###\n",
        "    d.trainable = True\n",
        "    fake_x = g.predict(x)\n",
        "    d_x = np.concatenate([x, fake_x], axis=0)\n",
        "    d_y = np.concatenate([np.zeros(len(x)), np.ones(len(fake_x))], axis=0)\n",
        "    d_loss = d.train_on_batch(d_x, d_y)\n",
        "    ### train generator ###\n",
        "    d.trainable = False \n",
        "    g_loss = gan_trainer.train_on_batch(x, y)\n",
        "    #g_loss include adv cnt enc loss, and what is last one ?\n",
        "\n",
        "    if i % 50 == 0:\n",
        "        print(f'niter: {i+1}, g_loss: {g_loss}, d_loss: {d_loss}')\n",
        "\n",
        "encoded = g_e.predict(x_test)\n",
        "gan_x = g.predict(x_test)\n",
        "encoded_gan = g_e.predict(gan_x)\n",
        "score = np.sum(np.absolute(encoded - encoded_gan), axis=-1)\n",
        "score = (score - np.min(score)) / (np.max(score) - np.min(score)) # map to 0~1\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 14, 5\n",
        "plt.scatter(range(len(x_test)), score, c=['skyblue' if x == 1 else 'pink' for x in y_test])\n",
        "\n",
        "#sum 100000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnEXAj3wds5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H37xz2Svds3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "niter = 400000\n",
        "bz = 32\n",
        "\n",
        "for i in range(niter):\n",
        "    ### get batch x, y ###\n",
        "    x, y = train_data_generator.__next__()\n",
        "    ### train disciminator ###\n",
        "    d.trainable = True\n",
        "    fake_x = g.predict(x)\n",
        "    d_x = np.concatenate([x, fake_x], axis=0)\n",
        "    d_y = np.concatenate([np.zeros(len(x)), np.ones(len(fake_x))], axis=0)\n",
        "    d_loss = d.train_on_batch(d_x, d_y)\n",
        "    ### train generator ###\n",
        "    d.trainable = False \n",
        "    g_loss = gan_trainer.train_on_batch(x, y)\n",
        "    #g_loss include adv cnt enc loss, and what is last one ?\n",
        "\n",
        "    if i % 50 == 0:\n",
        "        print(f'niter: {i+1}, g_loss: {g_loss}, d_loss: {d_loss}')\n",
        "\n",
        "encoded = g_e.predict(x_test)\n",
        "gan_x = g.predict(x_test)\n",
        "encoded_gan = g_e.predict(gan_x)\n",
        "score = np.sum(np.absolute(encoded - encoded_gan), axis=-1)\n",
        "score = (score - np.min(score)) / (np.max(score) - np.min(score)) # map to 0~1\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 14, 5\n",
        "plt.scatter(range(len(x_test)), score, c=['skyblue' if x == 1 else 'pink' for x in y_test])\n",
        "\n",
        "##sum 500000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oXtlu5Yds0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l525foydsx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2I0rCBOdsvc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1BJTYardssn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aqZd2TXdsqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYQMuvTsWeyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Bb4LMQCWevp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i=4\n",
        "y_test[i:i+1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4RTuE-Ud8k9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = np.reshape(gan_x[i:i+1], (64, 64))\n",
        "image = image * 127 + 127\n",
        "plt.imshow(image.astype(np.uint8), cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zToWEVgjgfkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = np.reshape(x_test[i:i+1], (64, 64))\n",
        "image = image * 127 + 127\n",
        "plt.imshow(image.astype(np.uint8), cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYPlM_WbXS_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL_aOfNoXS7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i=1\n",
        "y_test[i:i+1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je4Qa6nBXS4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = np.reshape(gan_x[i:i+1], (64, 64))\n",
        "image = image * 127 + 127\n",
        "plt.imshow(image.astype(np.uint8), cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqdaqOr4XS2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = np.reshape(x_test[i:i+1], (64, 64))\n",
        "image = image * 127 + 127\n",
        "plt.imshow(image.astype(np.uint8), cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr3nLb5ZXLKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F86rRcE6XLId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#x_ok = x_train[y_train == 1]\n",
        "\n",
        "(x_train2, y_train2), (x_test2, y_test2) = mnist.load_data()\n",
        "\n",
        "x_test_7 = x_test2[y_test2 == 7]\n",
        "x_test_7 = reshape_x(x_test_7)\n",
        "\n",
        "x_test_1 = x_test2[y_test2 == 1]\n",
        "x_test_1 = reshape_x(x_test_1)\n",
        "\n",
        "y_test_7 = y_test2[y_test2 == 7]\n",
        "y_test_1 = y_test2[y_test2 == 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2jWaF0wXLF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMX1nec8XLC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded = g_e.predict(x_test_7)\n",
        "gan_x = g.predict(x_test_7)\n",
        "encoded_gan = g_e.predict(gan_x)\n",
        "score = np.sum(np.absolute(encoded - encoded_gan), axis=-1)\n",
        "score = (score - np.min(score)) / (np.max(score) - np.min(score)) # map to 0~1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUHM2iUvXLAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score_7=score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbQ-mfaqXK-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded = g_e.predict(x_test_1)\n",
        "gan_x = g.predict(x_test_1)\n",
        "encoded_gan = g_e.predict(gan_x)\n",
        "score = np.sum(np.absolute(encoded - encoded_gan), axis=-1)\n",
        "score = (score - np.min(score)) / (np.max(score) - np.min(score)) # map to 0~1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdXtiRTgXK7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score_ok_1=score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJv0Ks4UXK4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "sns.set()\n",
        "sns.set_style('whitegrid')\n",
        "sns.set_palette('Set1')\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "labels = ['lab_ok_1', 'lab_7']\n",
        "ax.hist(score_ok_1, bins=50, alpha=0.6,label=labels[0])\n",
        "ax.hist(score_7, bins=50, alpha=0.6,label=labels[1])\n",
        "ax.set_xlabel('length [cm]')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsU_YFsX07u5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpxnvyhb07nR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#x_ok = x_train[y_train == 1]\n",
        "\n",
        "(x_train2, y_train2), (x_test2, y_test2) = mnist.load_data()\n",
        "\n",
        "x_test_5 = x_test2[y_test2 == 5]\n",
        "x_test_5 = reshape_x(x_test_5)\n",
        "\n",
        "x_test_1 = x_test2[y_test2 == 1]\n",
        "x_test_1 = reshape_x(x_test_1)\n",
        "\n",
        "y_test_5 = y_test2[y_test2 == 5]\n",
        "y_test_1 = y_test2[y_test2 == 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG6_Vdh507kj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_boAOiF07iC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded = g_e.predict(x_test_5)\n",
        "gan_x = g.predict(x_test_5)\n",
        "encoded_gan = g_e.predict(gan_x)\n",
        "score = np.sum(np.absolute(encoded - encoded_gan), axis=-1)\n",
        "score = (score - np.min(score)) / (np.max(score) - np.min(score)) # map to 0~1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzInw5ntIoTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score_5=score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKFExEaFItQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded = g_e.predict(x_test_1)\n",
        "gan_x = g.predict(x_test_1)\n",
        "encoded_gan = g_e.predict(gan_x)\n",
        "score = np.sum(np.absolute(encoded - encoded_gan), axis=-1)\n",
        "score = (score - np.min(score)) / (np.max(score) - np.min(score)) # map to 0~1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46WdK58yItFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score_1=score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eX6OVBHW2hQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkfV6d038xJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set()\n",
        "sns.set_style('whitegrid')\n",
        "sns.set_palette('Set1')\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "labels = ['lab_1', 'lab_5']\n",
        "ax.hist(score_1, bins=50, alpha=0.6,label=labels[0])\n",
        "ax.hist(score_5, bins=50, alpha=0.6,label=labels[1])\n",
        "ax.set_xlabel('length [cm]')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJSryTBz8xGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#学習回数が少なすぎると1の画像が正規分布しない\n",
        "#何回学習したら綺麗に分かれるのか上で検証してみる"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmM88bMV8xDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g.save_weights('g.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWmzUU1h8wsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g_e.save_weights('g_e.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpAgajjv8wpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUofLBaeYfV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbmNGaiUYfTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsPEaY0tYfRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz-cbZuYYfOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QynkGaF_YfMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import layers\n",
        "import keras\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NASvhisDYfJo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "width = 64\n",
        "height = 64\n",
        "channels = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYr7mGDpYfG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_layer = layers.Input(name='input', shape=(height, width, channels))\n",
        "\n",
        "# Encoder\n",
        "x = layers.Conv2D(32, (5,5), strides=(1,1), padding='same', name='conv_1', kernel_regularizer = 'l2')(input_layer)\n",
        "x = layers.LeakyReLU(name='leaky_1')(x)\n",
        "\n",
        "x = layers.Conv2D(64, (3,3), strides=(2,2), padding='same', name='conv_2', kernel_regularizer = 'l2')(x)\n",
        "x = layers.BatchNormalization(name='norm_1')(x)\n",
        "x = layers.LeakyReLU(name='leaky_2')(x)\n",
        "\n",
        "\n",
        "x = layers.Conv2D(128, (3,3), strides=(2,2), padding='same', name='conv_3', kernel_regularizer = 'l2')(x)\n",
        "x = layers.BatchNormalization(name='norm_2')(x)\n",
        "x = layers.LeakyReLU(name='leaky_3')(x)\n",
        "\n",
        "\n",
        "x = layers.Conv2D(128, (3,3), strides=(2,2), padding='same', name='conv_4', kernel_regularizer = 'l2')(x)\n",
        "x = layers.BatchNormalization(name='norm_3')(x)\n",
        "x = layers.LeakyReLU(name='leaky_4')(x)\n",
        "\n",
        "x = layers.GlobalAveragePooling2D(name='g_encoder_output')(x)\n",
        "\n",
        "g_e = keras.models.Model(inputs=input_layer, outputs=x)\n",
        "\n",
        "g_e.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol-K6uYPYfEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_layer = layers.Input(name='input', shape=(height, width, channels))\n",
        "\n",
        "x = g_e(input_layer)\n",
        "\n",
        "y = layers.Dense(width * width * 2, name='dense')(x) # 2 = 128 / 8 / 8\n",
        "y = layers.Reshape((width//8, width//8, 128), name='de_reshape')(y)\n",
        "\n",
        "y = layers.Conv2DTranspose(128, (3,3), strides=(2,2), padding='same', name='deconv_1', kernel_regularizer = 'l2')(y)\n",
        "y = layers.LeakyReLU(name='de_leaky_1')(y)\n",
        "\n",
        "y = layers.Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', name='deconv_2', kernel_regularizer = 'l2')(y)\n",
        "y = layers.LeakyReLU(name='de_leaky_2')(y)\n",
        "\n",
        "y = layers.Conv2DTranspose(32, (3,3), strides=(2,2), padding='same', name='deconv_3', kernel_regularizer = 'l2')(y)\n",
        "y = layers.LeakyReLU(name='de_leaky_3')(y)\n",
        "\n",
        "y = layers.Conv2DTranspose(channels, (1, 1), strides=(1,1), padding='same', name='decoder_deconv_output', kernel_regularizer = 'l2', activation='tanh')(y)\n",
        "\n",
        "g = keras.models.Model(inputs=input_layer, outputs=y)\n",
        "\n",
        "g.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXMn2bmBYfBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2sF3cdXYe_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqGiycIM8wnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g.load_weights('g.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izmrylBz8wk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g_e.load_weights('g_e.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPBDEdPsY9Dm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu2O6o1cY9BG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBKDAQirY8-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reshape_x(x):\n",
        "    new_x = np.empty((len(x), width, height))\n",
        "    for i, e in enumerate(x):\n",
        "        new_x[i] = cv2.resize(e, (width, height))\n",
        "    return np.expand_dims(new_x, axis=-1) / 127 - 1\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJY3JAoa8whx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_test_6 = x_test[y_test == 6]\n",
        "x_test_6 = reshape_x(x_test_6)\n",
        "\n",
        "x_test_1 = x_test[y_test == 1]\n",
        "x_test_1 = reshape_x(x_test_1)\n",
        "\n",
        "y_test_6 = y_test[y_test == 6]\n",
        "y_test_1 = y_test[y_test == 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQrdbtKJ8wfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded = g_e.predict(x_test_6)\n",
        "gan_x = g.predict(x_test_6)\n",
        "encoded_gan = g_e.predict(gan_x)\n",
        "score = np.sum(np.absolute(encoded - encoded_gan), axis=-1)\n",
        "score = (score - np.min(score)) / (np.max(score) - np.min(score)) # map to 0~1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOoPoQnQLaWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fin_weight_score_6=score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8zKlY3mLaTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAeJAyjrLaRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded = g_e.predict(x_test_1)\n",
        "gan_x = g.predict(x_test_1)\n",
        "encoded_gan = g_e.predict(gan_x)\n",
        "score = np.sum(np.absolute(encoded - encoded_gan), axis=-1)\n",
        "score = (score - np.min(score)) / (np.max(score) - np.min(score)) # map to 0~1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBU_zSJGLaN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fin_weight_score_1=score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JI6ZUxhLaJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anfv9OexLaF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set()\n",
        "sns.set_style('whitegrid')\n",
        "sns.set_palette('Set1')\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "labels = ['fin_weight_lab_1', 'fin_weight_lab_6']\n",
        "ax.hist(fin_weight_score_1, bins=50, alpha=0.6,label=labels[0])\n",
        "ax.hist(fin_weight_score_6, bins=50, alpha=0.6,label=labels[1])\n",
        "ax.set_xlabel('length [cm]')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBZAdWBiLaDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}